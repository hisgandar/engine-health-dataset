{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Datasets/engine_data.csv')\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the dataframe information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imputation to resolve class imbalance\n",
    "\n",
    "filter_1 = df[df['Engine Condition']==1]\n",
    "filter_0 = df[df['Engine Condition']==0]\n",
    "\n",
    "filter_1 = filter_1.drop(filter_1.sample(len(filter_1)-len(filter_0)).index).reset_index(drop=True)\n",
    "\n",
    "\n",
    "df = pd.concat([filter_0, filter_1])\n",
    "\n",
    "\n",
    "df['Engine Condition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.drop(columns=['Engine Condition']), df['Engine Condition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hist_plot(engine_health):\n",
    "\n",
    "    filtered_df = df[df['Engine Condition']==engine_health]\n",
    "    numeric_columns = filtered_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    \n",
    "    num_columns = len(numeric_columns)\n",
    "    fig, axes = plt.subplots(1, num_columns, figsize=(6 * num_columns, 10))\n",
    "\n",
    "    # If there's only one column, axes won't be a list, so we handle it separately\n",
    "    if num_columns == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Plotting histograms for each numeric column\n",
    "    for ax, col in zip(axes, numeric_columns):\n",
    "        filtered_df[col].hist(ax=ax, bins=15, edgecolor='black')\n",
    "        ax.set_title(f'{col} Histogram (Condition=1)')\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot(engine_health):\n",
    "    filtered_df = df[df['Engine Condition']==engine_health]\n",
    "    numeric_columns = filtered_df.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "    # Create histograms for each numeric column\n",
    "    num_columns = len(numeric_columns)\n",
    "    fig, axes = plt.subplots(1, num_columns, figsize=(6 * num_columns, 10))\n",
    "\n",
    "    # If there's only one column, axes won't be a list, so we handle it separately\n",
    "    if num_columns == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    # Plotting histograms for each numeric column\n",
    "    for ax, col in zip(axes, numeric_columns):\n",
    "        filtered_df[col].plot(kind='box' ,ax=ax)\n",
    "        ax.set_title(f'{col} Box Plot (Condition=1)')\n",
    "        ax.set_xlabel(col)\n",
    "        ax.set_ylabel('Frequency')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "box_plot(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train) #Remembers Mean and STD of the X_train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans = scaler.transform(X_train)  # Subtracts Mean and divides by STD from corresponding columns(each value)\n",
    "X_test_trans = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred=log_reg.predict(X_test_trans),y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(n_neighbors):\n",
    "  knn = KNeighborsClassifier(n_neighbors = n_neighbors)\n",
    "  knn.fit(X_train, y_train)\n",
    "\n",
    "  # Predict on the test set\n",
    "  y_pred = knn.predict(X_test)\n",
    "\n",
    "  # Calculate accuracy\n",
    "\n",
    "  return f1_score(y_test,y_pred)\n",
    "\n",
    "sizes = np.arange(1,100)\n",
    "\n",
    "f1 = [train_model(i) for i in sizes]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(sizes, f1, marker='o')\n",
    "plt.title('F1 Scores vs Model Size')\n",
    "plt.xlabel('Model Size')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "knn.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred=knn.predict(X_test_trans), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred=clf.predict(X_test_trans), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(gamma='auto')\n",
    "svc.fit(X_train_trans, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred=svc.predict(X_test_trans), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XG boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst = XGBClassifier()\n",
    "\n",
    "bst.fit(X_train_trans, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred=bst.predict(X_test_trans), y_true=y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
